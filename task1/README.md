# 네트워크 지연 시간 측정 방법

클라이언트에서 서버로 패킷을 보내고, 서버에서 패킷을 받은 후에 클라이언트로 응답하는 시간을 측정은 다음과 같이 분석할 수 있습니다.

TCP 프로토콜을 사용하여 서버에서 클라이언트가 보낸 데이터를 읽고, 해당 데이터를 다시 클라이언트에게 보내는 구현을 했습니다. 클라이언트는 서버에 데이터를 보내고, 서버가 보낸 데이터를 받아 출력했습니다. 이를 위해 timestamp를 이용해서 클라이언트에서 서버로 패킷을 보내고, 서버에서 패킷을 받은 후 클라이언트로 응답하는 데 걸리는 시간을 측정해 네트워크 지연 결과를 관찰했습니다. 네트워크 지연 시간이 굉장히 빨라 차이를 관찰하기 쉽게끔 1000000값을 곱해주었습니다.

- 실행결과
    1. 단일 TCP 서버와 클라이언트 간의 통신 10회 결과
        - 평균 지연 시간 : 275μs
        - 최대 지연 시간 : 336μs
        - 최소 지연 시간 : 216μs

    2. 단일 TCP 서버와 클라이언트 간의 통신 20회 결과
    - 평균 지연 시간 : 260μs
    - 최대 지연 시간 : 341μs
    - 최소 지연 시간 : 116μs